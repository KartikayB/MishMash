{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_to_speech():\n",
    "    import pytesseract       \n",
    "    import pyttsx3 \n",
    "    from PIL import Image \n",
    "    from googletrans import Translator       \n",
    "    img = Image.open('text15.png')                                  \n",
    "    pytesseract.pytesseract.tesseract_cmd ='C:/Users/karti/AAAPython/MishMash/Tesseract-OCR/tesseract.exe'   \n",
    "    result = pytesseract.image_to_string(img)    \n",
    "    with open('abc.txt',mode ='w') as file:      \n",
    "\n",
    "                     file.write(result) \n",
    "                     print(result) \n",
    "\n",
    "    engine = pyttsx3.init()  \n",
    "    engine.say(result)                              \n",
    "    engine.runAndWait() \n",
    "    p = Translator()                       \n",
    "    k = p.translate(result,dest='hindi')       \n",
    "    return(k.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text():\n",
    "    import speech_recognition as sr \n",
    "    import pyttsx3  \n",
    "    r = sr.Recognizer()  \n",
    "    def SpeakText(command): \n",
    "        engine = pyttsx3.init() \n",
    "        engine.say(command)  \n",
    "        engine.runAndWait() \n",
    "    flag=1\n",
    "    while(flag):     \n",
    "        try: \n",
    "            with sr.Microphone() as source2:  \n",
    "                r.adjust_for_ambient_noise(source2, duration=0.2)  \n",
    "                audio2 = r.listen(source2) \n",
    "                MyText = r.recognize_google(audio2) \n",
    "                MyText = MyText.lower()\n",
    "                print(\"Did you say \",MyText) \n",
    "                SpeakText(MyText) \n",
    "                return MyText\n",
    "                flag=0\n",
    "        except sr.RequestError as e: \n",
    "            flag=0\n",
    "            print(\"Could not request results; {0}\".format(e))\n",
    "        except sr.UnknownValueError:\n",
    "            flag=0\n",
    "            print(\"unknown error occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saved_to_text():\n",
    "    import speech_recognition as sr \n",
    "\n",
    "    AUDIO_FILE =\"you-are-acting-so-weird.wav\" \n",
    "    r = sr.Recognizer() \n",
    "\n",
    "    with sr.AudioFile(AUDIO_FILE) as source: \n",
    "        audio = r.record(source)    \n",
    "    return(r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are acting so weird\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from tkinter.ttk import *\n",
    "window = Tk()\n",
    "\n",
    "window.title(\"The Converter\")\n",
    "\n",
    "\n",
    "window.geometry('1000x1000')\n",
    "window.configure(background='PeachPuff')\n",
    "\n",
    "\n",
    "res=\"\"\n",
    "\n",
    "lbl = Label(window, text=\"Helping Hand\", font=(\"georgia\", 30,\"bold\"),background=\"PeachPuff\")\n",
    "#lbl.grid(column=0, row=0)\n",
    "lbl.place(relx=0.5, rely=0.1, anchor=CENTER)\n",
    "def clicked():\n",
    "    res= image_to_speech()\n",
    "    lbl2 = Label(window, text=res, font=(\"Arial Bold\", 20,\"bold\"),background=\"PeachPuff\",borderwidth=2, relief=\"groove\")\n",
    "    lbl2.place(relx=0.5, rely=0.6, anchor=CENTER)\n",
    "    print(res)\n",
    "def clicked2():\n",
    "    res= speech_to_text()\n",
    "    lbl2 = Label(window, text=res, font=(\"Arial Bold\", 20,\"bold\"),background=\"PeachPuff\",borderwidth=2, relief=\"groove\")\n",
    "    lbl2.place(relx=0.5, rely=0.6, anchor=CENTER)\n",
    "    print(res)\n",
    "def clicked3():\n",
    "    res= saved_to_text()\n",
    "    lbl2 = Label(window, text=res, font=(\"Arial Bold\", 20,\"bold\"),background=\"PeachPuff\",borderwidth=2, relief=\"groove\")\n",
    "    lbl2.place(relx=0.5, rely=0.6, anchor=CENTER)\n",
    "    print(res)\n",
    "btn = Button(window, text=\"Image To Speech\", command=clicked,underline=2)\n",
    "btn.place(relx=0.1, rely=0.3,height=50,width=200)\n",
    "btn = Button(window, text=\"Speech To Text\", command=clicked2,underline=2)\n",
    "btn.place(relx=0.4, rely=0.3,height=50,width=200)\n",
    "btn = Button(window, text=\"Saved Audio File To Text\", command=clicked3,underline=2)\n",
    "btn.place(relx=0.7, rely=0.3,height=50,width=200)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The audio file contains: you are acting so weird\n"
     ]
    }
   ],
   "source": [
    "# def saved_to_text():\n",
    "#     import speech_recognition as sr \n",
    "\n",
    "#     AUDIO_FILE =\"you-are-acting-so-weird.wav\" \n",
    "#     r = sr.Recognizer() \n",
    "\n",
    "#     with sr.AudioFile(AUDIO_FILE) as source: \n",
    "#         audio = r.record(source)   \n",
    "#     print(\"The audio file contains: \" + r.recognize_google(audio)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import speech_recognition as sr \n",
    "# import pyttsx3  \n",
    "# r = sr.Recognizer()  \n",
    "# def SpeakText(command): \n",
    "#     engine = pyttsx3.init() \n",
    "#     engine.say(command)  \n",
    "#     engine.runAndWait() \n",
    "# flag=1\n",
    "# while(flag):     \n",
    "#     try: \n",
    "#         with sr.Microphone() as source2:  \n",
    "#             r.adjust_for_ambient_noise(source2, duration=0.2)  \n",
    "#             audio2 = r.listen(source2) \n",
    "#             MyText = r.recognize_google(audio2) \n",
    "#             MyText = MyText.lower()\n",
    "#             print(\"Did you say \",MyText) \n",
    "#             SpeakText(MyText) \n",
    "#             flag=0\n",
    "#     except sr.RequestError as e: \n",
    "#         flag=0\n",
    "#         print(\"Could not request results; {0}\".format(e))\n",
    "#     except sr.UnknownValueError:\n",
    "#         flag=0\n",
    "#         print(\"unknown error occured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytesseract       \n",
    "  \n",
    "# from PIL import Image     \n",
    "     \n",
    "# import pyttsx3            \n",
    "   \n",
    "# from googletrans import Translator       \n",
    "   \n",
    "# img = Image.open('text15.png')                          \n",
    "# pytesseract.pytesseract.tesseract_cmd ='C:/Program Files/Tesseract-OCR/tesseract.exe'   \n",
    "# result = pytesseract.image_to_string(img)    \n",
    "# with open('abc.txt',mode ='w') as file:      \n",
    "      \n",
    "#                  file.write(result) \n",
    "#                  print(result) \n",
    "\n",
    "# engine = pyttsx3.init()  \n",
    "# engine.say(result)                              \n",
    "# engine.runAndWait() \n",
    "# p = Translator()                       \n",
    "# k = p.translate(result,dest='hindi')       \n",
    "# print(k.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# subscription_key = 'REPLACE_WITH_YOUR_KEY'\n",
    "\n",
    "\n",
    "# def get_token(subscription_key):\n",
    "#     fetch_token_url = 'https://westus.api.cognitive.microsoft.com/sts/v1.0/issueToken'\n",
    "#     headers = {\n",
    "#         'Ocp-Apim-Subscription-Key': subscription_key\n",
    "#     }\n",
    "#     response = requests.post(fetch_token_url, headers=headers)\n",
    "#     access_token = str(response.text)\n",
    "#     print(access_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
